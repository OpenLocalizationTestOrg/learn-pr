The use of containers to develop and deploy software has become popular over the last few years. Containers make it easy to package and deploy an application with all its services to any compute environment. When your application meets higher demand, you can easily scale out your services by deploying additional container instances. Containers are also less resource intensive than virtual machines. This efficiency allows you to make better use of compute resources that will save you money.

The standard container management runtime is focused on managing individual containers. However, there are times where you'll want to scale and have multiple containers working together. Scaling multiple containers becomes challenging as several factors needs consideration when managing multiple containers. Suppose you need to handle load balancing, security, network connectivity, and deployment. To help make this process easier, it's common to use a container management platform such as Kubernetes.

Suppose you work at a fleet management company. Your company provides an asset tracking solution to customers worldwide. Your tracking solution is built and deployed as microservices. You're using containerized instances to quickly deploy into new customer regions and scale resources as needed to meet customer demands. You want to use a container orchestration platform that makes it simple to develop, deploy, and manage containerized applications.

Here, you'll see how Azure Kubernetes Service (AKS) makes it simple to manage a hosted Kubernetes environment in Azure. The goal is to help you decide if AKS is a good choice as a Kubernetes platform for your business.

## Learning objectives

In this module, you will:

- Evaluate whether Azure Kubernetes Service is an appropriate Kubernetes orchestration platform for you
- Describe how the components of Azure Kubernetes Service work to support compute container orchestration

## Prerequisites

- Basic understanding of microservices
