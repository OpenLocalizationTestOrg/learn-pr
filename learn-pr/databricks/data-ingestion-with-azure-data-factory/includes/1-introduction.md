Imagine you're part of an analytics team that gets a huge assignment to analyze crime data. The dataset that you receive contains detailed crime information for several major cities. But each city's dataset is formatted and structured differently and stored in different data stores. The cities also use different categories and terms for similar types of data. Your team needs to analyze all the datasets and report the aggregated number of crimes per month in each city.

Your team decides to use Azure Data Factory and Azure Databricks to ingest, transform, and aggregate the required data.

[!INCLUDE [azure-databricks-free-trial-note](../../../includes/azure-databricks-free-trial-note.md)]

## Learning objectives

In this module, you'll:

- Use Azure Data Factory to ingest data and create a Data Factory pipeline.
- Use copy activities within Data Factory to copy data from one location to another.
- Use Data Factory to direct data transformations by using a Databricks notebook activity.
